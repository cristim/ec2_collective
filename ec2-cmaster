#!/usr/bin/env python
# coding: utf-8

from boto.sqs import connect_to_region
from boto.exception import SQSError
import simplejson as json
import time
import signal
import sys
import getopt
import os
import random
import string
import logging
from multiprocessing import Process, Queue, active_children
from Queue import Empty

# Create queues
facts_pqueue = Queue()

# CFG FILE
CFILE='/etc/ec2_collective/ec2-cmaster.json'

# Added from https://gist.github.com/758430
class ColorizingStreamHandler(logging.StreamHandler):
    # color names to indices
    color_map = {
        'black': 0,
        'red': 1,
        'green': 2,
        'yellow': 3,
        'blue': 4,
        'magenta': 5,
        'cyan': 6,
        'white': 7,
    }

    #levels to (background, foreground, bold/intense)
    level_map = {
        logging.DEBUG: (None, 'blue', False),
        logging.INFO: (None, 'green', False),
        logging.WARNING: (None, 'yellow', False),
        logging.ERROR: (None, 'red', False),
        logging.CRITICAL: ('red', 'white', True),
    }
    csi = '\x1b['
    reset = '\x1b[0m'

    @property
    def is_tty(self):
        isatty = getattr(self.stream, 'isatty', None)
        return isatty and isatty()

    def emit(self, record):
        try:
            message = self.format(record)
            stream = self.stream
            if not self.is_tty:
                stream.write(message)
            else:
                self.output_colorized(message)
            stream.write(getattr(self, 'terminator', '\n'))
            self.flush()
        except (KeyboardInterrupt, SystemExit):
            raise
        except:
            self.handleError(record)

    def output_colorized(self, message):
        self.stream.write(message)

    def colorize(self, message, record):
        if record.levelno in self.level_map:
            bg, fg, bold = self.level_map[record.levelno]
            params = []
            if bg in self.color_map:
                params.append(str(self.color_map[bg] + 40))
            if fg in self.color_map:
                params.append(str(self.color_map[fg] + 30))
            if bold:
                params.append('1')
            if params:
                message = ''.join((self.csi, ';'.join(params),
                                   'm', message, self.reset))
        return message

    def format(self, record):
        message = logging.StreamHandler.format(self, record)
        if self.is_tty:
            # Don't colorize any traceback
            parts = message.split('\n', 1)
            parts[0] = self.colorize(parts[0], record)
            message = '\n'.join(parts)
        return message

def daemonize (stdin='/dev/null', stdout=sys.stdout, stderr=sys.stderr ):

    try:
        pid = os.fork( )
        if pid > 0:
            sys.exit(0) # Exit first parent.
    except OSError, e:
        sys.stderr.write("fork #1 failed: (%d) %s\n" % (e.errno, e.strerror))
        sys.exit(1)
    # Decouple from parent environment.
    os.chdir("/")
    os.umask(0)
    os.setsid( )
    # Perform second fork.
    try:
        pid = os.fork( )
        if pid > 0:
            sys.exit(0) # Exit second parent.
    except OSError, e:
        sys.stderr.write("fork #2 failed: (%d) %s\n" % (e.errno, e.strerror))
        sys.exit(1)
    # The process is now daemonized, redirect standard file descriptors.
    for f in sys.stdout, sys.stderr: f.flush( )
    si = file(stdin, 'r')
    so = file(stdout, 'a+')
    se = file(stderr, 'a+', 0)
    os.dup2(si.fileno( ), sys.stdin.fileno( ))
    os.dup2(so.fileno( ), sys.stdout.fileno( ))
    os.dup2(se.fileno( ), sys.stderr.fileno( ))

    sys.stderr.flush()
    sys.stdout.flush()

    return 

def get_config():
    if not os.path.exists(CFILE):
        print CFILE + ' file does not exist'
        sys.exit(1)

    try:
        fp = open(CFILE, 'r')
    except IOError, e:
        print ('Failed to open ' + CFILE + ' (%d) %s \n' % (e.errno, e.strerror))
        sys.exit(1)
    
    try:
        global CFG
        CFG=json.load(fp)
    except (TypeError, ValueError), e:
        print 'Error in configuration file'
        sys.exit(1)

def set_logging(logfile=False):

    log = logging.getLogger()
    logging.getLogger('boto').setLevel(logging.CRITICAL)

    if logfile is not False:

        if os.path.exists(os.path.dirname(logfile)):
            fh = logging.FileHandler(logfile)
            log.addHandler(fh)
        else:
            print >>sys.stderr, 'Log directory does not exist (' + os.path.dirname(logfile) + ')'
            sys.exit(1)

        fh_fmt = logging.Formatter("%(asctime)s %(message)s")
        fh.setFormatter(fh_fmt)

    if CFG['general']['log_level'] == 'INFO':
        log.setLevel(logging.INFO)
    elif CFG['general']['log_level'] == 'WARN':
        log.setLevel(logging.WARN)
    elif CFG['general']['log_level'] == 'ERROR':
        log.setLevel(logging.ERROR)
    elif CFG['general']['log_level'] == 'DEBUG':
        log.setLevel(logging.DEBUG)
    elif CFG['general']['log_level'] == 'CRITICAL':
        log.setLevel(logging.CRITICAL)

    log.addHandler(ColorizingStreamHandler(sys.stdout))

def usage():
    print >>sys.stderr, '    Usage:'
    print >>sys.stderr, '    ' + sys.argv[0] + ' -c <command>'
    print >>sys.stderr, '    ' + sys.argv[0] + ' -c <command> -l <path to logfile>\t output to console and logfile'
    print >>sys.stderr, '    ' + sys.argv[0] + ' -c <command> -w key=value\tAgent must match this fact'
    print >>sys.stderr, '    ' + sys.argv[0] + ' -c <command> -n key=value\tAgent must NOT match this fact'
    print >>sys.stderr, '    ' + sys.argv[0] + ' -c file://path/to/some/script\tSend file and make agent execute it'
    print >>sys.stderr, '    ' + sys.argv[0] + ' -c s3://bucket/script\tAsk agent to fetch script from s3 and execute'
    print >>sys.stderr, '    ' + sys.argv[0] + ' -c [file://|s3://] -p arg1 arg2\tSend arguments to file:// or s3:// scripts'
    print >>sys.stderr, '    ' + sys.argv[0] + ' -m \tGet a count on responding hosts'
    print >>sys.stderr, '    ' + sys.argv[0] + ' -q <queue prefix> -c <command>\tOverwrite default_queue_name'
    print >>sys.stderr, '    ' + sys.argv[0] + ' -c <command> -t <seconds>\tOverwrite default timeout for agent to respond'
    sys.exit(1)

def main():

    global MASTER_EC
    MASTER_EC=0

    # Get configuration
    get_config()

    # Defaults
    mode='ping'
    cmd=None
    wf=None
    wof=None
    timeout=int(CFG['general']['cmd_timeout'])
    timeout_set = False
    script_param=None
    logfile=False

    try:
        opts, args = getopt.getopt(sys.argv[1:], 'hc:w:n:t:p:q:ml:', ['help', 'command=', 'wf=', 'wc=', 'wof=', 'timeout=', 'script-parameters=', 'sqs-queue=', 'monitor', 'logfile='])
    except getopt.GetoptError, err:
        print >>sys.stderr, str(err) 
        return 1

    for o, a in opts:
        if o in ('-h', '--help'):
            usage()
        elif o in ('-c', '--command'):
            cmd = a
            if 'file://' in cmd:
                mode='script'
                cmd = cmd[7:]
            elif 's3://' in cmd:
                mode='s3'
                cmd = cmd[5:]
            else:
                mode='cli'
        elif o in ('-w', '--wf', '--wc'):
            if wf is not None:
                wf = wf + ',' + a
	    else:
                wf = a
        elif o in ('-n', '--wof'):
            if wof is not None:
                wof = wof + ',' + a
	    else:
                wof = a
        elif o in ('-t', '--timeout'):
            try:
                timeout = int(a)
                timeout_set = True
            except:
                print >>sys.stderr, 'Timeout value is not an integer'
                sys.exit(1)
        elif o in ('-p', '--script-parameters'):
            if mode in ['script', 's3']:
                script_param = a
        elif o in ('-q', '--sqs-queue-prefix'):
            CFG['aws']['default_queue_name'] = str(a)
        elif o in ('-m', '--monitor'):
            mode='count'
        elif o in ('-l', '--logfile'):
            logfile=a

    if mode is None:
        print >>sys.stderr, 'Please provide modetion'
        usage()

    if mode not in ['ping', 'count', 'cli', 'script', 's3' ]:
        print >>sys.stderr, 'Uknown mode: ' + str(a)
        usage()

    set_logging(logfile)

    run (mode, cmd, wf, wof, timeout, script_param)

# Signal handler
def delete_old_message_timeout(signum, frame):
    sys.exit(0)

# When timeout happens master_timeout definition executes raising an exception
signal.signal(signal.SIGALRM, delete_old_message_timeout)

def response_disect(responses, mode, pingresp, cmdresp ):

    for response in responses:
        if responses[response]['mode'] in ['ping', 'count']:
            pingresp.append(responses[response]['hostname'])
            if mode == 'ping':
                mode_ping_response (responses[response])
        else:
            cmdresp.append(responses[response]['hostname'])
            mode_cmd_response (responses[response])

    return (pingresp, cmdresp)

def mode_ping_response (response):
    hostname = str(response['hostname'])
    output = str(response['output'])

    response_time = round( (time.time() - float(output)) * 1000, 2 )
    response_str = hostname + ' time=' + str(response_time) + ' ms'

    logging.info(response_str)

def mode_cmd_response (response):

    global MASTER_EC

    hostname = str(response['hostname'])
    output = str(response['output'])
    rc = str(response['rc'])

    if int(rc) != 0:
	logging.debug('Setting master exit code to ' + str(rc) + ' in mode_cmd_response')
        MASTER_EC = int(rc)

    response_str = '>>>>>> ' + hostname + ' exit code: ('+str(rc)+'):\n' +  str(output)
 
    if int(rc) == 0: 
        logging.info(response_str)
    else:
        logging.warn(response_str)

def receive_facts ():

    start_time=int(time.time())

    conn = establish_sqs_conn()
    facts_queue = conn.get_queue(CFG['aws']['default_queue_name'] + CFG['aws']['facts_queue_suffix'])

    if facts_queue is None:
        logging.error('Unable to get ' + str(CFG['aws']['default_queue_name']) + str(CFG['aws']['facts_queue_suffix']) + ' queue by name')
        sys.exit(1)

    old_msgs = {}
    agent_facts_resp={}

    timeout=( CFG['general']['ping_timeout'] - 1 )
    while ( True ):
        agent_facts, old_msgs = pull_agent_facts (facts_queue, old_msgs)
        if len(agent_facts) > 0:
            logging.debug('Got agent ' + str(len(agent_facts)) + ' facts')
            agent_facts_resp.update(agent_facts)

        if ((time.time() - start_time) >= timeout):
            logging.debug('facts timeout reached ' + str(timeout) )
            break

    logging.debug('agent_facts_resp count ' + str(len(agent_facts_resp)))

    facts_pqueue.put(agent_facts_resp)

    sys.exit(0)

def pull_agent_facts (facts_queue, old_msgs ):

    logging.debug('Pulling agent facts')

    response = None
    responses = {}

    # Receive at least 1 message be fore continuing 
    rmsgs = facts_queue.get_messages(num_messages=10, visibility_timeout=0)

    # For each message we check for duplicate, and if it is a response to our org message
    for rmsg in rmsgs:

        # PUT FIRST Avoid duplicates 
        if rmsg.id in old_msgs:
            continue
        else:
            old_msgs[rmsg.id] = rmsg.id

        response=json.loads(rmsg.get_body())
        ec2_cagent_hostname = str(response['ec2_cagent_hostname'])

        # If it is from an agent we already handled
        if ec2_cagent_hostname in old_msgs:
            continue
        else:
            old_msgs[ec2_cagent_hostname] = ec2_cagent_hostname

        responses[ec2_cagent_hostname] = response

        logging.debug(response)

    logging.debug('Returning: ' + str(len(responses)) + ' responses')
    # Retrun all responses
    return (responses, old_msgs)

def receive_responses (read_queue, org_ids, mode, timeout, wf, wof ):

    ptimeout=CFG['general']['ping_timeout']
    total_responses = {}
    old_msgs = {}
    pingresp=[]
    cmdresp=[]
    agents_to_expect=0

    start_time=int(time.time())
    while ( True ):

        # Check the queue
        try:
            agent_facts_resp = facts_pqueue.get(False)
            logging.debug('facts read from facts_pqueue')
            agents_to_expect = count_agents(agent_facts_resp, wf, wof)
        except Empty:
            logging.debug('facts_pqueue is empty')

        responses, old_msgs = pull_msgs (read_queue, org_ids, old_msgs)
        if len(responses) > 0:
            (pingresp, cmdresp) = response_disect(responses, mode, pingresp, cmdresp )

        # Add the command timeout to break if we never get a ping answer or cmd answer
        if ((int(time.time()) - start_time) >= timeout):
            logging.warn('cmd_timeout timeout reached ' + str(timeout) )
            logging.debug('Setting master exit code to 1 because of cmd timeout' )
            global MASTER_EC
            MASTER_EC=1
            break

        # Discover with ping or agents_to_expect 
        if agents_to_expect == 0:
            if mode in [ 'ping','count' ]:
                if (int(time.time()) - start_time) >= ptimeout:
                    logging.debug('Ping timeout reached (' + str(ptimeout) + ')')
                    break
            else:
                if (int(time.time()) - start_time) >= ptimeout and len(cmdresp) >= len(pingresp):
                    logging.debug('Ping timeout reached (' + str(ptimeout) + ') and got response from all')
                    break
        else:
            # We can add another level of reliability
            if mode in [ 'ping','count' ]:
                if (int(time.time()) - start_time) >= ptimeout and len(pingresp) >= agents_to_expect:
                    logging.debug('Ping timeout reached (' + str(ptimeout) + ') and expected agents replied')
                    break
            else:
                if (int(time.time()) - start_time) >= ptimeout and len(pingresp) >= agents_to_expect and len(cmdresp) >= len(pingresp):
                    logging.debug('Ping timeout reached (' + str(ptimeout) + ') and got response from all expected agents')
                    break

    logging.debug('pingresp, cmdresp: ' + str(len(pingresp)) + ', ' + str(len(cmdresp)))

    return (pingresp, cmdresp, agents_to_expect)

def pull_msgs (read_queue, org_ids, old_msgs ):

    response = None
    responses = {}

    # Receive at least 1 message be fore continuing 
    rmsgs = read_queue.get_messages(num_messages=10, visibility_timeout=1)

    # For each message we check for duplicate, and if it is a response to our org message
    for rmsg in rmsgs:

        # PUT FIRST Avoid duplicates 
        if rmsg.id in old_msgs:
            continue
        else:
            old_msgs[rmsg.id] = rmsg.id

        response=json.loads(rmsg.get_body())
        msg_id = str(response['msg_id'])

        # Is it a response to our original request
        if msg_id not in org_ids:
            # Dont handle it again
            old_msgs[rmsg.id] = rmsg.id
            continue

        responses[rmsg.id] = response

        # We're done with the message - delete it
        if not read_queue.delete_message(rmsg):
            logging.error('Failed to delete reponse message')

        logging.debug(response)

    logging.debug('Returning: ' + str(len(responses)) + ' responses')
    # Retrun all responses
    return (responses, old_msgs)

def delete_org_message (msg_ids):

    daemonize (stdin='/dev/null', stdout='/dev/null', stderr='/dev/null' )

    conn = establish_sqs_conn()
    write_queue = conn.get_queue(CFG['aws']['default_queue_name'] + CFG['aws']['write_queue_suffix'])

    if write_queue is None:
        logging.error('Unable to get write_queue url by name')
        sys.exit(1)

    signal.alarm(CFG['general']['clean_timeout'])

    # We simply try to delete old messages for 'clean_timeout' period
    while ( True ):
        pull_org_msgs (write_queue, msg_ids)

    signal.alarm(0)

def pull_org_msgs(write_queue, msg_ids):

    # Pick up written message and delete it
    wmsgs = write_queue.get_messages(num_messages=10, visibility_timeout=1)
    
    for wmsg in wmsgs:
    
        if wmsg.id in msg_ids:
            if not write_queue.delete_message(wmsg):
                logging.error('Failed to delete original command message')

def fact_lookup (wf, wof, yaml_facts ):
    # Same engine from agent

    # True - Skip
    # False - Process

    # WOF
    # Return True if we have the fact ( just on should skip message )
    # Return False if we don't have the fact

    # WF
    # Return False if we have all the fact ( all facts must match )
    # Return True if we don't have the fact

    # If nothing is set we process message
    if wf is None and wof is None:
        logging.debug('Agent match - message contains no facts')
        return False

    # If wof is in facts we return True ( skip message )
    if wof is not None:
        wof = wof.split(',')
        for f in wof:
            if '=' in f:
                f = f.split('=')
    
                if (f[0] in yaml_facts) and (yaml_facts[f[0]] == f[1]):
                    logging.debug('Agent skip - wof matched')
                    return True
            else:
                if f in yaml_facts:
                    logging.debug('Agent skip - wof matched')
    		    return True

    # Without is set but we did not find it, if wf is not set we return False ( process message )
    if wf is None:
        logging.debug('Agent match - no wof match and no wf')
        return False

    # If all wf is in facts we return False ( process message )
    no_match=0
    wf = wf.split(',')
    for f in wf:
        if '=' in f:
            f = f.split('=')
   
            if (f[0] not in yaml_facts) or (yaml_facts[f[0]] != f[1]):
                no_match += 1
        else:
            if f not in yaml_facts:
                no_match += 1

    if no_match == 0 :
        # All facts was found ( process message )
        logging.debug('Agent match - wf matched')
        return False
    else:
        # Facts set was not found - return True ( skip message )
        logging.debug('Agent skip - no wf match')
        return True

def count_agents (agent_facts_resp, wf, wof):
    count=0
    for agent in agent_facts_resp:
        if fact_lookup (wf, wof, agent_facts_resp[agent]) == False:
            count += 1

    logging.debug(str(count) + ' agent matched')

    return count

def id_generator(size=10, chars=string.ascii_uppercase + string.digits):
    return ''.join(random.choice(chars) for x in range(size))

def dict_to_sqs_obj(message, write_queue):

    message_json=json.dumps(message)

    if len(message) >= 65536:
        logging.error ('Message is too big to put on SQS')
        sys.exit(1)

    try:
        message = write_queue.new_message(message_json)
    except:
        logging.error('Failed to create message object - check queue name')
        sys.exit(1)

    return message

def write_msg (write_queue, dict_message):

    message=dict_to_sqs_obj(dict_message, write_queue)
    org_ids={}

    written=False
    for i in range(0, 3):
        try:
            org = write_queue.write(message)
        except:
            logging.error('Failed to write command message')
            sys.exit(1)

        if org.id is None:
            logging.error('Failed to write 1 command message')
        else:
            written=True
            org_ids[org.id] = org.id

    if written is True:
        return org_ids
    else:
        logging.error('Failed to write any command messages')
        sys.exit(1)

def inhale_script (script_file):
    if not os.path.exists(script_file):
        logging.error(str(script_file) + ' file does not exist')
        sys.exit(1)

    f = open(script_file, 'r')

    return f.read()

def establish_sqs_conn ():

    # Connect with key, secret and region
    try:
        conn = connect_to_region(CFG['aws']['region'])
    except:
        logging.error('Could not connect to SQS - check your authentication')
        sys.exit(1)

    return conn

def run(mode, cmd, wf, wof, timeout, script_param):
    global MASTER_EC

    payload = None

    if mode == 'script':
        payload = inhale_script(cmd)
        cmd = os.path.basename(cmd)

    responses={}
    ping_responses={}
    org_ids={}

    # Fork worker for handling facts queue
    if CFG['general']['use_facts_queue'] == True:
        P = Process(target=receive_facts, args=())
        P.daemon=True
        P.start()
        logging.debug('Forking facts receiver with pid ' + str(P.pid))

    conn = establish_sqs_conn()

    # Configure correct queue names
    read_queue = conn.get_queue(CFG['aws']['default_queue_name'] + CFG['aws']['read_queue_suffix'])
    write_queue = conn.get_queue(CFG['aws']['default_queue_name'] + CFG['aws']['write_queue_suffix'])

    if read_queue is None or write_queue is None:
        logging.error('Unable to get queue url by name')
        exit(1)

    # Construct message, send and receive
    message={'mode':mode,'cmd':cmd, 'ts':time.time(), 'wf':wf, 'wof':wof, 'batch_msg_id':id_generator()}
    logging.debug('Message is ' + str(message))
    org_ids.update (write_msg(write_queue, message))
    (pingresp, cmdresp, agents_to_expect ) = receive_responses (read_queue, org_ids, mode, timeout, wf, wof )

    # Delete original messags
    D = Process(target=delete_org_message, args=(org_ids,))
    D.daemon=False
    D.start()
    logging.debug('Forking process to delete old message ' + str(D.pid))

    # monitoring mode - output count of ping replies and exit
    if mode == 'count':
        logging.info(str(len(pingresp)))
        sys.exit(0)

    # If we're in command mode we need to display hosts that did not respond
    if mode in ['cli', 'script', 's3'] and len(pingresp) > len(cmdresp):
        for hostname in pingresp:
            if hostname not in cmdresp:
                logging.warn('Timeout in response from: ' + hostname)

        # If some of the expected servers did not answer we exit 1
	logging.debug('Setting master exit code to 1 because discovery and response count differ')
        MASTER_EC=1

    if len(cmdresp) == 0 and len(pingresp) == 0:
	logging.debug('Setting master exit code to 1 because of no responses' )
        MASTER_EC=1

    output_str='Got response from ' + str(len(cmdresp)) + ' out of ' + str(len(pingresp)) + '/' + str(agents_to_expect) + ' (discovered/expected)' + ' - exit code ('+str(MASTER_EC)+')'
    if int(MASTER_EC) == 0:
        logging.info(output_str)
    else:
        logging.warn(output_str)

    sys.exit(MASTER_EC)

if __name__ == "__main__":
    sys.exit(main())
